{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST Keras.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8crIC3Y3njG"
      },
      "source": [
        "#Section 4\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITwO9SL8fh4N"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense , Activation\n",
        "from tensorflow.keras.layers import Dropout\n",
        "\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils, to_categorical\n",
        "from sklearn.model_selection import KFold"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G8BOiwKlop_a"
      },
      "source": [
        "def load_data():\n",
        "    \n",
        "    return mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVciDIoaqny_"
      },
      "source": [
        "def prepare_data(train_images, train_labels, test_images, test_labels):\n",
        "\n",
        "    x_train = train_images.reshape((60000, 784))\n",
        "    x_train = x_train.astype('float32')/255\n",
        "\n",
        "    x_test = test_images.reshape((10000, 784))\n",
        "    x_test = x_test.astype('float32')/255\n",
        "\n",
        "    #one hot encoding\n",
        "    y_train =  to_categorical(train_labels) \n",
        "    y_test = to_categorical(test_labels)\n",
        "\n",
        "    return (x_train, y_train, x_test, y_test )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AXM3H9Yvwq-l"
      },
      "source": [
        "def model(x_train, y_train, x_test, y_test ):\n",
        "    \n",
        "    kfold = KFold(n_splits=10, shuffle=True)\n",
        "    fold_no = 0\n",
        "    history = ''\n",
        "    \n",
        "    # Define per-fold score containers\n",
        "    acc_per_fold = []\n",
        "    loss_per_fold = []\n",
        "    for train_index, test_index in kfold.split(x_train):\n",
        "        print(len(x_train[train_index]))\n",
        "        model = Sequential()\n",
        "\n",
        "        model.add(Dense(128, activation='relu', input_shape=(784,)))\n",
        "        model.add(Dropout(0.2))\n",
        "        model.add(Dense(64, activation='relu'))\n",
        "        model.add(Dense(10, activation = 'softmax'))\n",
        "\n",
        "        model.summary()\n",
        "\n",
        "        model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "        history = model.fit(x_train[train_index], y_train[train_index],\n",
        "                batch_size=2048, epochs=25, verbose=1,\n",
        "                validation_data=(x_train[test_index], y_train[test_index]))\n",
        "\n",
        "        print('------------------------------------------------------------------------')\n",
        "        print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "        # Generate generalization metrics\n",
        "        scores = model.evaluate(x_train[test_index], y_train[test_index], verbose=0)\n",
        "        print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "        acc_per_fold.append(scores[1] * 100)\n",
        "        loss_per_fold.append(scores[0])\n",
        "\n",
        "        fold_no += 1\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print('Score per fold')\n",
        "    for i in range(0, len(acc_per_fold)):\n",
        "        print('------------------------------------------------------------------------')\n",
        "        print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print('Average scores for all folds:')\n",
        "    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "    print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "    print('------------------------------------------------------------------------')\n",
        "\n",
        "    score = model.evaluate(x_test, y_test)\n",
        "    print('Test loss :', score[0])\n",
        "    print('Test accuracy:', score[1] * 100)\n",
        "\n",
        "    return history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GCzZHF3yJC4x"
      },
      "source": [
        "def plot(history):\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()\n",
        "    # summarize history for loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'test'], loc='upper left')\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7K4I3_XOTOA"
      },
      "source": [
        "def main():\n",
        "    (train_images, train_labels), (test_images, test_labels) = load_data()\n",
        "   \n",
        "    x_train, y_train, x_test, y_test = prepare_data(train_images, train_labels, test_images, test_labels)\n",
        "\n",
        "    history = model(x_train, y_train, x_test, y_test)\n",
        "    \n",
        "    plot(history)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WDua5JAOaLJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "0200221d-f817-4fea-dd69-e5d128bc7cce"
      },
      "source": [
        "main()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "54000\n",
            "Model: \"sequential_12\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_30 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_31 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_32 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 109,386\n",
            "Trainable params: 109,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "27/27 [==============================] - 1s 33ms/step - loss: 1.3622 - accuracy: 0.6115 - val_loss: 0.5242 - val_accuracy: 0.8600\n",
            "Epoch 2/25\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.4741 - accuracy: 0.8589 - val_loss: 0.3262 - val_accuracy: 0.9068\n",
            "Epoch 3/25\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.3426 - accuracy: 0.9004 - val_loss: 0.2674 - val_accuracy: 0.9262\n",
            "Epoch 4/25\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.2869 - accuracy: 0.9158 - val_loss: 0.2324 - val_accuracy: 0.9348\n",
            "Epoch 5/25\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.2507 - accuracy: 0.9274 - val_loss: 0.2083 - val_accuracy: 0.9423\n",
            "Epoch 6/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.2240 - accuracy: 0.9355 - val_loss: 0.1891 - val_accuracy: 0.9465\n",
            "Epoch 7/25\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.2027 - accuracy: 0.9409 - val_loss: 0.1729 - val_accuracy: 0.9512\n",
            "Epoch 8/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1854 - accuracy: 0.9462 - val_loss: 0.1613 - val_accuracy: 0.9552\n",
            "Epoch 9/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1714 - accuracy: 0.9498 - val_loss: 0.1504 - val_accuracy: 0.9580\n",
            "Epoch 10/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1583 - accuracy: 0.9533 - val_loss: 0.1418 - val_accuracy: 0.9618\n",
            "Epoch 11/25\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1487 - accuracy: 0.9565 - val_loss: 0.1348 - val_accuracy: 0.9618\n",
            "Epoch 12/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1381 - accuracy: 0.9593 - val_loss: 0.1261 - val_accuracy: 0.9658\n",
            "Epoch 13/25\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1304 - accuracy: 0.9619 - val_loss: 0.1222 - val_accuracy: 0.9668\n",
            "Epoch 14/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1220 - accuracy: 0.9636 - val_loss: 0.1164 - val_accuracy: 0.9687\n",
            "Epoch 15/25\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1158 - accuracy: 0.9656 - val_loss: 0.1147 - val_accuracy: 0.9693\n",
            "Epoch 16/25\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1097 - accuracy: 0.9671 - val_loss: 0.1090 - val_accuracy: 0.9697\n",
            "Epoch 17/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1025 - accuracy: 0.9697 - val_loss: 0.1050 - val_accuracy: 0.9700\n",
            "Epoch 18/25\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.0964 - accuracy: 0.9712 - val_loss: 0.1027 - val_accuracy: 0.9708\n",
            "Epoch 19/25\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.0937 - accuracy: 0.9726 - val_loss: 0.1000 - val_accuracy: 0.9715\n",
            "Epoch 20/25\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.0890 - accuracy: 0.9735 - val_loss: 0.0961 - val_accuracy: 0.9722\n",
            "Epoch 21/25\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.0854 - accuracy: 0.9737 - val_loss: 0.0941 - val_accuracy: 0.9727\n",
            "Epoch 22/25\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.0803 - accuracy: 0.9759 - val_loss: 0.0963 - val_accuracy: 0.9735\n",
            "Epoch 23/25\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.0773 - accuracy: 0.9758 - val_loss: 0.0902 - val_accuracy: 0.9738\n",
            "Epoch 24/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0738 - accuracy: 0.9780 - val_loss: 0.0914 - val_accuracy: 0.9727\n",
            "Epoch 25/25\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.0710 - accuracy: 0.9788 - val_loss: 0.0918 - val_accuracy: 0.9730\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 0 ...\n",
            "Score for fold 0: loss of 0.09176914393901825; accuracy of 97.29999899864197%\n",
            "54000\n",
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_33 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_34 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_35 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 109,386\n",
            "Trainable params: 109,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "27/27 [==============================] - 1s 33ms/step - loss: 1.3342 - accuracy: 0.6175 - val_loss: 0.5078 - val_accuracy: 0.8622\n",
            "Epoch 2/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.4762 - accuracy: 0.8578 - val_loss: 0.3154 - val_accuracy: 0.9112\n",
            "Epoch 3/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.3427 - accuracy: 0.9004 - val_loss: 0.2583 - val_accuracy: 0.9263\n",
            "Epoch 4/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.2881 - accuracy: 0.9167 - val_loss: 0.2198 - val_accuracy: 0.9393\n",
            "Epoch 5/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.2491 - accuracy: 0.9278 - val_loss: 0.1950 - val_accuracy: 0.9467\n",
            "Epoch 6/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.2232 - accuracy: 0.9356 - val_loss: 0.1751 - val_accuracy: 0.9505\n",
            "Epoch 7/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.2014 - accuracy: 0.9413 - val_loss: 0.1607 - val_accuracy: 0.9542\n",
            "Epoch 8/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1816 - accuracy: 0.9477 - val_loss: 0.1469 - val_accuracy: 0.9587\n",
            "Epoch 9/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1680 - accuracy: 0.9516 - val_loss: 0.1361 - val_accuracy: 0.9613\n",
            "Epoch 10/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1552 - accuracy: 0.9547 - val_loss: 0.1262 - val_accuracy: 0.9637\n",
            "Epoch 11/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.1445 - accuracy: 0.9571 - val_loss: 0.1185 - val_accuracy: 0.9670\n",
            "Epoch 12/25\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1337 - accuracy: 0.9610 - val_loss: 0.1120 - val_accuracy: 0.9680\n",
            "Epoch 13/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1277 - accuracy: 0.9619 - val_loss: 0.1069 - val_accuracy: 0.9690\n",
            "Epoch 14/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1198 - accuracy: 0.9643 - val_loss: 0.1025 - val_accuracy: 0.9717\n",
            "Epoch 15/25\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1117 - accuracy: 0.9668 - val_loss: 0.0978 - val_accuracy: 0.9723\n",
            "Epoch 16/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1049 - accuracy: 0.9681 - val_loss: 0.0943 - val_accuracy: 0.9738\n",
            "Epoch 17/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1008 - accuracy: 0.9704 - val_loss: 0.0923 - val_accuracy: 0.9737\n",
            "Epoch 18/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0934 - accuracy: 0.9721 - val_loss: 0.0875 - val_accuracy: 0.9757\n",
            "Epoch 19/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0909 - accuracy: 0.9726 - val_loss: 0.0862 - val_accuracy: 0.9753\n",
            "Epoch 20/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0848 - accuracy: 0.9751 - val_loss: 0.0833 - val_accuracy: 0.9760\n",
            "Epoch 21/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0814 - accuracy: 0.9756 - val_loss: 0.0818 - val_accuracy: 0.9768\n",
            "Epoch 22/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0778 - accuracy: 0.9766 - val_loss: 0.0789 - val_accuracy: 0.9775\n",
            "Epoch 23/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0749 - accuracy: 0.9770 - val_loss: 0.0797 - val_accuracy: 0.9772\n",
            "Epoch 24/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0713 - accuracy: 0.9783 - val_loss: 0.0775 - val_accuracy: 0.9777\n",
            "Epoch 25/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0691 - accuracy: 0.9784 - val_loss: 0.0757 - val_accuracy: 0.9780\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Score for fold 1: loss of 0.07566146552562714; accuracy of 97.79999852180481%\n",
            "54000\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_36 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 109,386\n",
            "Trainable params: 109,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "27/27 [==============================] - 1s 34ms/step - loss: 1.3998 - accuracy: 0.6073 - val_loss: 0.5439 - val_accuracy: 0.8543\n",
            "Epoch 2/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.4818 - accuracy: 0.8579 - val_loss: 0.3153 - val_accuracy: 0.9095\n",
            "Epoch 3/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.3422 - accuracy: 0.9006 - val_loss: 0.2588 - val_accuracy: 0.9237\n",
            "Epoch 4/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.2821 - accuracy: 0.9180 - val_loss: 0.2226 - val_accuracy: 0.9337\n",
            "Epoch 5/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.2418 - accuracy: 0.9296 - val_loss: 0.1940 - val_accuracy: 0.9412\n",
            "Epoch 6/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.2156 - accuracy: 0.9373 - val_loss: 0.1757 - val_accuracy: 0.9440\n",
            "Epoch 7/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1954 - accuracy: 0.9447 - val_loss: 0.1630 - val_accuracy: 0.9503\n",
            "Epoch 8/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1780 - accuracy: 0.9488 - val_loss: 0.1475 - val_accuracy: 0.9532\n",
            "Epoch 9/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1626 - accuracy: 0.9520 - val_loss: 0.1390 - val_accuracy: 0.9580\n",
            "Epoch 10/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1520 - accuracy: 0.9561 - val_loss: 0.1319 - val_accuracy: 0.9585\n",
            "Epoch 11/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1419 - accuracy: 0.9585 - val_loss: 0.1248 - val_accuracy: 0.9598\n",
            "Epoch 12/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1320 - accuracy: 0.9617 - val_loss: 0.1178 - val_accuracy: 0.9628\n",
            "Epoch 13/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1233 - accuracy: 0.9639 - val_loss: 0.1124 - val_accuracy: 0.9643\n",
            "Epoch 14/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1157 - accuracy: 0.9659 - val_loss: 0.1092 - val_accuracy: 0.9660\n",
            "Epoch 15/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1084 - accuracy: 0.9682 - val_loss: 0.1056 - val_accuracy: 0.9678\n",
            "Epoch 16/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1046 - accuracy: 0.9686 - val_loss: 0.0990 - val_accuracy: 0.9697\n",
            "Epoch 17/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0991 - accuracy: 0.9708 - val_loss: 0.0959 - val_accuracy: 0.9703\n",
            "Epoch 18/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0930 - accuracy: 0.9724 - val_loss: 0.0925 - val_accuracy: 0.9708\n",
            "Epoch 19/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0859 - accuracy: 0.9746 - val_loss: 0.0899 - val_accuracy: 0.9717\n",
            "Epoch 20/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0840 - accuracy: 0.9745 - val_loss: 0.0878 - val_accuracy: 0.9713\n",
            "Epoch 21/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0804 - accuracy: 0.9757 - val_loss: 0.0859 - val_accuracy: 0.9723\n",
            "Epoch 22/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0747 - accuracy: 0.9779 - val_loss: 0.0838 - val_accuracy: 0.9728\n",
            "Epoch 23/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0743 - accuracy: 0.9771 - val_loss: 0.0837 - val_accuracy: 0.9723\n",
            "Epoch 24/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0686 - accuracy: 0.9794 - val_loss: 0.0805 - val_accuracy: 0.9743\n",
            "Epoch 25/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0662 - accuracy: 0.9798 - val_loss: 0.0801 - val_accuracy: 0.9747\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Score for fold 2: loss of 0.08008912205696106; accuracy of 97.46666550636292%\n",
            "54000\n",
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_39 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 109,386\n",
            "Trainable params: 109,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "27/27 [==============================] - 1s 34ms/step - loss: 1.3570 - accuracy: 0.6145 - val_loss: 0.5291 - val_accuracy: 0.8542\n",
            "Epoch 2/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.4631 - accuracy: 0.8610 - val_loss: 0.3356 - val_accuracy: 0.9027\n",
            "Epoch 3/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.3330 - accuracy: 0.9021 - val_loss: 0.2752 - val_accuracy: 0.9195\n",
            "Epoch 4/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.2801 - accuracy: 0.9176 - val_loss: 0.2382 - val_accuracy: 0.9290\n",
            "Epoch 5/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.2435 - accuracy: 0.9291 - val_loss: 0.2108 - val_accuracy: 0.9377\n",
            "Epoch 6/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.2157 - accuracy: 0.9374 - val_loss: 0.1906 - val_accuracy: 0.9437\n",
            "Epoch 7/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1940 - accuracy: 0.9426 - val_loss: 0.1729 - val_accuracy: 0.9480\n",
            "Epoch 8/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.1770 - accuracy: 0.9487 - val_loss: 0.1581 - val_accuracy: 0.9532\n",
            "Epoch 9/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1621 - accuracy: 0.9518 - val_loss: 0.1479 - val_accuracy: 0.9558\n",
            "Epoch 10/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1501 - accuracy: 0.9559 - val_loss: 0.1414 - val_accuracy: 0.9590\n",
            "Epoch 11/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1388 - accuracy: 0.9586 - val_loss: 0.1337 - val_accuracy: 0.9598\n",
            "Epoch 12/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1293 - accuracy: 0.9618 - val_loss: 0.1244 - val_accuracy: 0.9618\n",
            "Epoch 13/25\n",
            "27/27 [==============================] - 1s 31ms/step - loss: 0.1212 - accuracy: 0.9642 - val_loss: 0.1189 - val_accuracy: 0.9647\n",
            "Epoch 14/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1131 - accuracy: 0.9664 - val_loss: 0.1164 - val_accuracy: 0.9653\n",
            "Epoch 15/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1075 - accuracy: 0.9683 - val_loss: 0.1108 - val_accuracy: 0.9680\n",
            "Epoch 16/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1004 - accuracy: 0.9694 - val_loss: 0.1080 - val_accuracy: 0.9677\n",
            "Epoch 17/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0968 - accuracy: 0.9713 - val_loss: 0.1060 - val_accuracy: 0.9688\n",
            "Epoch 18/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0911 - accuracy: 0.9727 - val_loss: 0.1028 - val_accuracy: 0.9695\n",
            "Epoch 19/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0887 - accuracy: 0.9735 - val_loss: 0.0989 - val_accuracy: 0.9700\n",
            "Epoch 20/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0822 - accuracy: 0.9759 - val_loss: 0.0984 - val_accuracy: 0.9718\n",
            "Epoch 21/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0778 - accuracy: 0.9764 - val_loss: 0.0954 - val_accuracy: 0.9717\n",
            "Epoch 22/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0740 - accuracy: 0.9776 - val_loss: 0.0932 - val_accuracy: 0.9733\n",
            "Epoch 23/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0735 - accuracy: 0.9774 - val_loss: 0.0919 - val_accuracy: 0.9722\n",
            "Epoch 24/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0688 - accuracy: 0.9791 - val_loss: 0.0913 - val_accuracy: 0.9725\n",
            "Epoch 25/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0670 - accuracy: 0.9796 - val_loss: 0.0892 - val_accuracy: 0.9740\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Score for fold 3: loss of 0.08918743580579758; accuracy of 97.39999771118164%\n",
            "54000\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_42 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 109,386\n",
            "Trainable params: 109,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "27/27 [==============================] - 1s 34ms/step - loss: 1.2907 - accuracy: 0.6379 - val_loss: 0.5104 - val_accuracy: 0.8508\n",
            "Epoch 2/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.4686 - accuracy: 0.8589 - val_loss: 0.3268 - val_accuracy: 0.9095\n",
            "Epoch 3/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.3411 - accuracy: 0.9005 - val_loss: 0.2654 - val_accuracy: 0.9243\n",
            "Epoch 4/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.2837 - accuracy: 0.9176 - val_loss: 0.2301 - val_accuracy: 0.9345\n",
            "Epoch 5/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.2448 - accuracy: 0.9275 - val_loss: 0.2025 - val_accuracy: 0.9410\n",
            "Epoch 6/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.2162 - accuracy: 0.9374 - val_loss: 0.1808 - val_accuracy: 0.9460\n",
            "Epoch 7/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1967 - accuracy: 0.9426 - val_loss: 0.1664 - val_accuracy: 0.9513\n",
            "Epoch 8/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1790 - accuracy: 0.9468 - val_loss: 0.1545 - val_accuracy: 0.9553\n",
            "Epoch 9/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1644 - accuracy: 0.9519 - val_loss: 0.1411 - val_accuracy: 0.9582\n",
            "Epoch 10/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1521 - accuracy: 0.9546 - val_loss: 0.1377 - val_accuracy: 0.9577\n",
            "Epoch 11/25\n",
            "27/27 [==============================] - 1s 31ms/step - loss: 0.1419 - accuracy: 0.9583 - val_loss: 0.1272 - val_accuracy: 0.9613\n",
            "Epoch 12/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1313 - accuracy: 0.9604 - val_loss: 0.1203 - val_accuracy: 0.9627\n",
            "Epoch 13/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1261 - accuracy: 0.9623 - val_loss: 0.1130 - val_accuracy: 0.9638\n",
            "Epoch 14/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1168 - accuracy: 0.9651 - val_loss: 0.1091 - val_accuracy: 0.9662\n",
            "Epoch 15/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1101 - accuracy: 0.9672 - val_loss: 0.1087 - val_accuracy: 0.9658\n",
            "Epoch 16/25\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.1076 - accuracy: 0.9676 - val_loss: 0.1029 - val_accuracy: 0.9677\n",
            "Epoch 17/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1011 - accuracy: 0.9699 - val_loss: 0.1000 - val_accuracy: 0.9672\n",
            "Epoch 18/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0956 - accuracy: 0.9718 - val_loss: 0.0934 - val_accuracy: 0.9705\n",
            "Epoch 19/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0931 - accuracy: 0.9720 - val_loss: 0.0931 - val_accuracy: 0.9705\n",
            "Epoch 20/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0870 - accuracy: 0.9736 - val_loss: 0.0904 - val_accuracy: 0.9697\n",
            "Epoch 21/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0839 - accuracy: 0.9745 - val_loss: 0.0882 - val_accuracy: 0.9715\n",
            "Epoch 22/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0802 - accuracy: 0.9756 - val_loss: 0.0870 - val_accuracy: 0.9737\n",
            "Epoch 23/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0766 - accuracy: 0.9770 - val_loss: 0.0852 - val_accuracy: 0.9727\n",
            "Epoch 24/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0740 - accuracy: 0.9774 - val_loss: 0.0834 - val_accuracy: 0.9738\n",
            "Epoch 25/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0701 - accuracy: 0.9788 - val_loss: 0.0842 - val_accuracy: 0.9732\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Score for fold 4: loss of 0.08422033488750458; accuracy of 97.31666445732117%\n",
            "54000\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_45 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_46 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_47 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 109,386\n",
            "Trainable params: 109,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "27/27 [==============================] - 1s 33ms/step - loss: 1.3008 - accuracy: 0.6474 - val_loss: 0.5041 - val_accuracy: 0.8553\n",
            "Epoch 2/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.4564 - accuracy: 0.8624 - val_loss: 0.3187 - val_accuracy: 0.9075\n",
            "Epoch 3/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.3248 - accuracy: 0.9059 - val_loss: 0.2590 - val_accuracy: 0.9247\n",
            "Epoch 4/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.2727 - accuracy: 0.9217 - val_loss: 0.2224 - val_accuracy: 0.9357\n",
            "Epoch 5/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.2364 - accuracy: 0.9326 - val_loss: 0.2034 - val_accuracy: 0.9382\n",
            "Epoch 6/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.2143 - accuracy: 0.9382 - val_loss: 0.1811 - val_accuracy: 0.9442\n",
            "Epoch 7/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.1918 - accuracy: 0.9447 - val_loss: 0.1664 - val_accuracy: 0.9490\n",
            "Epoch 8/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1744 - accuracy: 0.9500 - val_loss: 0.1550 - val_accuracy: 0.9515\n",
            "Epoch 9/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1599 - accuracy: 0.9537 - val_loss: 0.1448 - val_accuracy: 0.9552\n",
            "Epoch 10/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1490 - accuracy: 0.9567 - val_loss: 0.1370 - val_accuracy: 0.9577\n",
            "Epoch 11/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1380 - accuracy: 0.9591 - val_loss: 0.1279 - val_accuracy: 0.9607\n",
            "Epoch 12/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1286 - accuracy: 0.9622 - val_loss: 0.1245 - val_accuracy: 0.9633\n",
            "Epoch 13/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1210 - accuracy: 0.9634 - val_loss: 0.1165 - val_accuracy: 0.9645\n",
            "Epoch 14/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1117 - accuracy: 0.9673 - val_loss: 0.1125 - val_accuracy: 0.9660\n",
            "Epoch 15/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1051 - accuracy: 0.9681 - val_loss: 0.1072 - val_accuracy: 0.9678\n",
            "Epoch 16/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1015 - accuracy: 0.9693 - val_loss: 0.1049 - val_accuracy: 0.9678\n",
            "Epoch 17/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0969 - accuracy: 0.9711 - val_loss: 0.1018 - val_accuracy: 0.9695\n",
            "Epoch 18/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0913 - accuracy: 0.9724 - val_loss: 0.0985 - val_accuracy: 0.9710\n",
            "Epoch 19/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0871 - accuracy: 0.9735 - val_loss: 0.1000 - val_accuracy: 0.9703\n",
            "Epoch 20/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0817 - accuracy: 0.9748 - val_loss: 0.0970 - val_accuracy: 0.9722\n",
            "Epoch 21/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0796 - accuracy: 0.9763 - val_loss: 0.0934 - val_accuracy: 0.9722\n",
            "Epoch 22/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0755 - accuracy: 0.9772 - val_loss: 0.0901 - val_accuracy: 0.9728\n",
            "Epoch 23/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0722 - accuracy: 0.9783 - val_loss: 0.0896 - val_accuracy: 0.9738\n",
            "Epoch 24/25\n",
            "27/27 [==============================] - 1s 28ms/step - loss: 0.0694 - accuracy: 0.9790 - val_loss: 0.0868 - val_accuracy: 0.9743\n",
            "Epoch 25/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0651 - accuracy: 0.9800 - val_loss: 0.0857 - val_accuracy: 0.9750\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Score for fold 5: loss of 0.08569899201393127; accuracy of 97.50000238418579%\n",
            "54000\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_48 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout_16 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_49 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_50 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 109,386\n",
            "Trainable params: 109,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "27/27 [==============================] - 1s 34ms/step - loss: 1.3535 - accuracy: 0.6153 - val_loss: 0.5494 - val_accuracy: 0.8455\n",
            "Epoch 2/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.4736 - accuracy: 0.8596 - val_loss: 0.3454 - val_accuracy: 0.9008\n",
            "Epoch 3/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.3407 - accuracy: 0.9013 - val_loss: 0.2784 - val_accuracy: 0.9197\n",
            "Epoch 4/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.2808 - accuracy: 0.9190 - val_loss: 0.2357 - val_accuracy: 0.9315\n",
            "Epoch 5/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.2412 - accuracy: 0.9304 - val_loss: 0.2052 - val_accuracy: 0.9422\n",
            "Epoch 6/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.2147 - accuracy: 0.9382 - val_loss: 0.1872 - val_accuracy: 0.9472\n",
            "Epoch 7/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1946 - accuracy: 0.9422 - val_loss: 0.1717 - val_accuracy: 0.9502\n",
            "Epoch 8/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1746 - accuracy: 0.9499 - val_loss: 0.1610 - val_accuracy: 0.9530\n",
            "Epoch 9/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1622 - accuracy: 0.9530 - val_loss: 0.1491 - val_accuracy: 0.9567\n",
            "Epoch 10/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1505 - accuracy: 0.9563 - val_loss: 0.1396 - val_accuracy: 0.9592\n",
            "Epoch 11/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.1399 - accuracy: 0.9594 - val_loss: 0.1340 - val_accuracy: 0.9612\n",
            "Epoch 12/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.1312 - accuracy: 0.9616 - val_loss: 0.1268 - val_accuracy: 0.9627\n",
            "Epoch 13/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.1227 - accuracy: 0.9644 - val_loss: 0.1208 - val_accuracy: 0.9645\n",
            "Epoch 14/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1161 - accuracy: 0.9659 - val_loss: 0.1205 - val_accuracy: 0.9643\n",
            "Epoch 15/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1097 - accuracy: 0.9678 - val_loss: 0.1129 - val_accuracy: 0.9665\n",
            "Epoch 16/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.1053 - accuracy: 0.9689 - val_loss: 0.1106 - val_accuracy: 0.9655\n",
            "Epoch 17/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.1005 - accuracy: 0.9703 - val_loss: 0.1038 - val_accuracy: 0.9685\n",
            "Epoch 18/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0940 - accuracy: 0.9728 - val_loss: 0.1008 - val_accuracy: 0.9698\n",
            "Epoch 19/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0891 - accuracy: 0.9748 - val_loss: 0.1001 - val_accuracy: 0.9690\n",
            "Epoch 20/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0864 - accuracy: 0.9746 - val_loss: 0.0975 - val_accuracy: 0.9698\n",
            "Epoch 21/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0804 - accuracy: 0.9757 - val_loss: 0.0957 - val_accuracy: 0.9705\n",
            "Epoch 22/25\n",
            "27/27 [==============================] - 1s 32ms/step - loss: 0.0794 - accuracy: 0.9768 - val_loss: 0.0937 - val_accuracy: 0.9722\n",
            "Epoch 23/25\n",
            "27/27 [==============================] - 1s 31ms/step - loss: 0.0752 - accuracy: 0.9776 - val_loss: 0.0922 - val_accuracy: 0.9717\n",
            "Epoch 24/25\n",
            "27/27 [==============================] - 1s 32ms/step - loss: 0.0715 - accuracy: 0.9791 - val_loss: 0.0903 - val_accuracy: 0.9712\n",
            "Epoch 25/25\n",
            "27/27 [==============================] - 1s 32ms/step - loss: 0.0700 - accuracy: 0.9793 - val_loss: 0.0875 - val_accuracy: 0.9740\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 6 ...\n",
            "Score for fold 6: loss of 0.0874909907579422; accuracy of 97.39999771118164%\n",
            "54000\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_51 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_52 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_53 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 109,386\n",
            "Trainable params: 109,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "27/27 [==============================] - 1s 36ms/step - loss: 1.3415 - accuracy: 0.6079 - val_loss: 0.5334 - val_accuracy: 0.8515\n",
            "Epoch 2/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.4750 - accuracy: 0.8581 - val_loss: 0.3253 - val_accuracy: 0.9083\n",
            "Epoch 3/25\n",
            "27/27 [==============================] - 1s 31ms/step - loss: 0.3396 - accuracy: 0.9005 - val_loss: 0.2642 - val_accuracy: 0.9245\n",
            "Epoch 4/25\n",
            "27/27 [==============================] - 1s 31ms/step - loss: 0.2841 - accuracy: 0.9175 - val_loss: 0.2276 - val_accuracy: 0.9360\n",
            "Epoch 5/25\n",
            "27/27 [==============================] - 1s 33ms/step - loss: 0.2478 - accuracy: 0.9288 - val_loss: 0.2036 - val_accuracy: 0.9433\n",
            "Epoch 6/25\n",
            "27/27 [==============================] - 1s 32ms/step - loss: 0.2229 - accuracy: 0.9357 - val_loss: 0.1840 - val_accuracy: 0.9463\n",
            "Epoch 7/25\n",
            "27/27 [==============================] - 1s 32ms/step - loss: 0.2026 - accuracy: 0.9417 - val_loss: 0.1682 - val_accuracy: 0.9498\n",
            "Epoch 8/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.1859 - accuracy: 0.9461 - val_loss: 0.1564 - val_accuracy: 0.9540\n",
            "Epoch 9/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1722 - accuracy: 0.9495 - val_loss: 0.1445 - val_accuracy: 0.9567\n",
            "Epoch 10/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1596 - accuracy: 0.9532 - val_loss: 0.1372 - val_accuracy: 0.9587\n",
            "Epoch 11/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1484 - accuracy: 0.9574 - val_loss: 0.1288 - val_accuracy: 0.9618\n",
            "Epoch 12/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1388 - accuracy: 0.9590 - val_loss: 0.1224 - val_accuracy: 0.9637\n",
            "Epoch 13/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.1278 - accuracy: 0.9629 - val_loss: 0.1149 - val_accuracy: 0.9653\n",
            "Epoch 14/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1237 - accuracy: 0.9642 - val_loss: 0.1097 - val_accuracy: 0.9677\n",
            "Epoch 15/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.1166 - accuracy: 0.9659 - val_loss: 0.1049 - val_accuracy: 0.9680\n",
            "Epoch 16/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.1088 - accuracy: 0.9681 - val_loss: 0.1013 - val_accuracy: 0.9683\n",
            "Epoch 17/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.1058 - accuracy: 0.9692 - val_loss: 0.0977 - val_accuracy: 0.9708\n",
            "Epoch 18/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0979 - accuracy: 0.9714 - val_loss: 0.0967 - val_accuracy: 0.9715\n",
            "Epoch 19/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0945 - accuracy: 0.9718 - val_loss: 0.0919 - val_accuracy: 0.9727\n",
            "Epoch 20/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0897 - accuracy: 0.9728 - val_loss: 0.0890 - val_accuracy: 0.9735\n",
            "Epoch 21/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0841 - accuracy: 0.9746 - val_loss: 0.0862 - val_accuracy: 0.9740\n",
            "Epoch 22/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0822 - accuracy: 0.9755 - val_loss: 0.0843 - val_accuracy: 0.9755\n",
            "Epoch 23/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0768 - accuracy: 0.9769 - val_loss: 0.0828 - val_accuracy: 0.9763\n",
            "Epoch 24/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0751 - accuracy: 0.9770 - val_loss: 0.0801 - val_accuracy: 0.9758\n",
            "Epoch 25/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.0715 - accuracy: 0.9784 - val_loss: 0.0772 - val_accuracy: 0.9758\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 7 ...\n",
            "Score for fold 7: loss of 0.07719504088163376; accuracy of 97.58333563804626%\n",
            "54000\n",
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_54 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout_18 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_55 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_56 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 109,386\n",
            "Trainable params: 109,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "27/27 [==============================] - 1s 34ms/step - loss: 1.2967 - accuracy: 0.6493 - val_loss: 0.5049 - val_accuracy: 0.8547\n",
            "Epoch 2/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.4493 - accuracy: 0.8660 - val_loss: 0.3312 - val_accuracy: 0.8973\n",
            "Epoch 3/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.3288 - accuracy: 0.9040 - val_loss: 0.2738 - val_accuracy: 0.9165\n",
            "Epoch 4/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.2751 - accuracy: 0.9201 - val_loss: 0.2398 - val_accuracy: 0.9260\n",
            "Epoch 5/25\n",
            "27/27 [==============================] - 1s 31ms/step - loss: 0.2395 - accuracy: 0.9298 - val_loss: 0.2109 - val_accuracy: 0.9372\n",
            "Epoch 6/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.2119 - accuracy: 0.9384 - val_loss: 0.1909 - val_accuracy: 0.9430\n",
            "Epoch 7/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.1905 - accuracy: 0.9451 - val_loss: 0.1755 - val_accuracy: 0.9473\n",
            "Epoch 8/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.1738 - accuracy: 0.9496 - val_loss: 0.1620 - val_accuracy: 0.9523\n",
            "Epoch 9/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.1613 - accuracy: 0.9527 - val_loss: 0.1535 - val_accuracy: 0.9545\n",
            "Epoch 10/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.1489 - accuracy: 0.9563 - val_loss: 0.1436 - val_accuracy: 0.9578\n",
            "Epoch 11/25\n",
            "27/27 [==============================] - 1s 29ms/step - loss: 0.1384 - accuracy: 0.9595 - val_loss: 0.1367 - val_accuracy: 0.9598\n",
            "Epoch 12/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.1292 - accuracy: 0.9623 - val_loss: 0.1316 - val_accuracy: 0.9602\n",
            "Epoch 13/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.1209 - accuracy: 0.9650 - val_loss: 0.1251 - val_accuracy: 0.9625\n",
            "Epoch 14/25\n",
            "27/27 [==============================] - 1s 31ms/step - loss: 0.1143 - accuracy: 0.9662 - val_loss: 0.1214 - val_accuracy: 0.9635\n",
            "Epoch 15/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.1086 - accuracy: 0.9675 - val_loss: 0.1145 - val_accuracy: 0.9643\n",
            "Epoch 16/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.1025 - accuracy: 0.9695 - val_loss: 0.1121 - val_accuracy: 0.9640\n",
            "Epoch 17/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0977 - accuracy: 0.9708 - val_loss: 0.1077 - val_accuracy: 0.9655\n",
            "Epoch 18/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0912 - accuracy: 0.9727 - val_loss: 0.1060 - val_accuracy: 0.9675\n",
            "Epoch 19/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0865 - accuracy: 0.9738 - val_loss: 0.1062 - val_accuracy: 0.9662\n",
            "Epoch 20/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0839 - accuracy: 0.9746 - val_loss: 0.1008 - val_accuracy: 0.9677\n",
            "Epoch 21/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0798 - accuracy: 0.9761 - val_loss: 0.0969 - val_accuracy: 0.9692\n",
            "Epoch 22/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0770 - accuracy: 0.9776 - val_loss: 0.0953 - val_accuracy: 0.9693\n",
            "Epoch 23/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0727 - accuracy: 0.9782 - val_loss: 0.0939 - val_accuracy: 0.9705\n",
            "Epoch 24/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0704 - accuracy: 0.9786 - val_loss: 0.0934 - val_accuracy: 0.9708\n",
            "Epoch 25/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0688 - accuracy: 0.9789 - val_loss: 0.0922 - val_accuracy: 0.9708\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 8 ...\n",
            "Score for fold 8: loss of 0.09215834736824036; accuracy of 97.08333611488342%\n",
            "54000\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_57 (Dense)             (None, 128)               100480    \n",
            "_________________________________________________________________\n",
            "dropout_19 (Dropout)         (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_58 (Dense)             (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dense_59 (Dense)             (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 109,386\n",
            "Trainable params: 109,386\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/25\n",
            "27/27 [==============================] - 1s 35ms/step - loss: 1.3157 - accuracy: 0.6272 - val_loss: 0.5334 - val_accuracy: 0.8512\n",
            "Epoch 2/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.4797 - accuracy: 0.8577 - val_loss: 0.3369 - val_accuracy: 0.9052\n",
            "Epoch 3/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.3427 - accuracy: 0.9007 - val_loss: 0.2728 - val_accuracy: 0.9247\n",
            "Epoch 4/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.2820 - accuracy: 0.9193 - val_loss: 0.2359 - val_accuracy: 0.9338\n",
            "Epoch 5/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.2449 - accuracy: 0.9295 - val_loss: 0.2079 - val_accuracy: 0.9410\n",
            "Epoch 6/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.2176 - accuracy: 0.9374 - val_loss: 0.1883 - val_accuracy: 0.9457\n",
            "Epoch 7/25\n",
            "27/27 [==============================] - 1s 31ms/step - loss: 0.1944 - accuracy: 0.9445 - val_loss: 0.1732 - val_accuracy: 0.9487\n",
            "Epoch 8/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.1766 - accuracy: 0.9488 - val_loss: 0.1599 - val_accuracy: 0.9515\n",
            "Epoch 9/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.1631 - accuracy: 0.9527 - val_loss: 0.1512 - val_accuracy: 0.9540\n",
            "Epoch 10/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.1519 - accuracy: 0.9558 - val_loss: 0.1445 - val_accuracy: 0.9570\n",
            "Epoch 11/25\n",
            "27/27 [==============================] - 1s 31ms/step - loss: 0.1413 - accuracy: 0.9589 - val_loss: 0.1362 - val_accuracy: 0.9582\n",
            "Epoch 12/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.1350 - accuracy: 0.9603 - val_loss: 0.1296 - val_accuracy: 0.9598\n",
            "Epoch 13/25\n",
            "27/27 [==============================] - 1s 32ms/step - loss: 0.1246 - accuracy: 0.9634 - val_loss: 0.1250 - val_accuracy: 0.9603\n",
            "Epoch 14/25\n",
            "27/27 [==============================] - 1s 34ms/step - loss: 0.1178 - accuracy: 0.9657 - val_loss: 0.1228 - val_accuracy: 0.9625\n",
            "Epoch 15/25\n",
            "27/27 [==============================] - 1s 33ms/step - loss: 0.1121 - accuracy: 0.9663 - val_loss: 0.1159 - val_accuracy: 0.9640\n",
            "Epoch 16/25\n",
            "27/27 [==============================] - 1s 32ms/step - loss: 0.1063 - accuracy: 0.9682 - val_loss: 0.1112 - val_accuracy: 0.9663\n",
            "Epoch 17/25\n",
            "27/27 [==============================] - 1s 34ms/step - loss: 0.0999 - accuracy: 0.9702 - val_loss: 0.1095 - val_accuracy: 0.9662\n",
            "Epoch 18/25\n",
            "27/27 [==============================] - 1s 32ms/step - loss: 0.0943 - accuracy: 0.9720 - val_loss: 0.1056 - val_accuracy: 0.9667\n",
            "Epoch 19/25\n",
            "27/27 [==============================] - 1s 31ms/step - loss: 0.0913 - accuracy: 0.9726 - val_loss: 0.1031 - val_accuracy: 0.9677\n",
            "Epoch 20/25\n",
            "27/27 [==============================] - 1s 31ms/step - loss: 0.0868 - accuracy: 0.9738 - val_loss: 0.1009 - val_accuracy: 0.9678\n",
            "Epoch 21/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0829 - accuracy: 0.9751 - val_loss: 0.1024 - val_accuracy: 0.9690\n",
            "Epoch 22/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0791 - accuracy: 0.9763 - val_loss: 0.0959 - val_accuracy: 0.9695\n",
            "Epoch 23/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0757 - accuracy: 0.9775 - val_loss: 0.0967 - val_accuracy: 0.9687\n",
            "Epoch 24/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0731 - accuracy: 0.9782 - val_loss: 0.0938 - val_accuracy: 0.9697\n",
            "Epoch 25/25\n",
            "27/27 [==============================] - 1s 30ms/step - loss: 0.0695 - accuracy: 0.9791 - val_loss: 0.0923 - val_accuracy: 0.9707\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 9 ...\n",
            "Score for fold 9: loss of 0.09229005873203278; accuracy of 97.06666469573975%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 0.09176914393901825 - Accuracy: 97.29999899864197%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 0.07566146552562714 - Accuracy: 97.79999852180481%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 0.08008912205696106 - Accuracy: 97.46666550636292%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 0.08918743580579758 - Accuracy: 97.39999771118164%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 0.08422033488750458 - Accuracy: 97.31666445732117%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 6 - Loss: 0.08569899201393127 - Accuracy: 97.50000238418579%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 7 - Loss: 0.0874909907579422 - Accuracy: 97.39999771118164%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 8 - Loss: 0.07719504088163376 - Accuracy: 97.58333563804626%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 9 - Loss: 0.09215834736824036 - Accuracy: 97.08333611488342%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 10 - Loss: 0.09229005873203278 - Accuracy: 97.06666469573975%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 97.39166617393494 (+- 0.20873295566262787)\n",
            "> Loss: 0.0855760931968689\n",
            "------------------------------------------------------------------------\n",
            "313/313 [==============================] - 0s 1ms/step - loss: 0.0813 - accuracy: 0.9757\n",
            "Test loss : 0.08129781484603882\n",
            "Test accuracy: 97.57000207901001\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}